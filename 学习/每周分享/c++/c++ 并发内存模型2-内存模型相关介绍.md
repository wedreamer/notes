# c++ 并发内存模型 2-内存模型相关介绍

-   内存模型是什么
-   为什么需要内存模型
-   c++ 内存模型设计都会涉及到什么
-   c++ 内存模型与 java 实现思路相关差异
-   编译器都需要做什么
-   其他的一些问题

## 内存模型

在计算中，内存模型描述了线程通过内存的交互以及它们对数据的共享使用。

> 深入理解 Java 虚拟机
> 在程序执行的过程中，cpu 至少要与内存交互，如读取运算数据、存储运算结果等，这个 I/O 操作很难消除。由于计算机的存储设备与 cpu 的运算速度有几个数量级的差距，所以现代计算机系统不得不加入一层或者多层使读写速度尽可能接近 cpu 运算速度的高速缓存来作为内存与 cpu 的缓冲。将运算需要使用的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存中，这样 cpu 就无需等待缓存的内存读写了。

> 基于高速缓存的存储交互解决了 cpu 和内存速度之间的矛盾，也为计算机系统带来更高的复杂度，引入了一个新的问题：缓存一致性。在多路 cpu 系统中，每个 cpu 都有自己的高速缓存，它们共享同一主内存，这种系统被称为共享内存多核系统。当多个 cpu 的运算任务都涉及同一块主内存区域时，将可能导致各自的缓存数据不一致。为了解决这个问题，需要各个 cpu 访问缓存时遵循一些协议，在读写时根据协议来进行操作，具体协议有 MSI、MESI、MOSI、Synapse、Firefly 及 Dragon Protocol 等。由此产生了“内存模型”，可以理解为在**特定的操作协议下，对特定的内存或高速缓存进行读写访问的过程抽象。不同架构的物理机器可以拥有不一样的内存模型**，而 jvm 也有自己的内存模型（java memory model），与内存访问操作及硬件的缓存操作具有高度可类比性。

> 除了增加高速缓存之外，为了使 cpu 内存的运算单元能进行被充分利用，cpu 可能会对输入代码进行乱序执行优化，cpu 会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但并不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致，因此如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与 cpu 的乱序执行优化类似，jvm 的即时编译器中也有指令重排序优化（可以禁止指令重排序）。

> jmm 的主要目的是定义程序中各种变量的访问规则，即关注在 vm 中把变量值存储到内存和从内存中取出变量值这样的底层细节。此处的变量包括了实例字段、静态字段和构成数组对象的元素，但是不包括局部变量和方法参数，因为后者是线程私有的，不会被共享，自然不会存在竞争问题。为了获取更好的执行效果，jmm 没有限制执行引擎使用 cpu 的特定寄存器或缓存来和主内存进行交互，也没有限制即时编译器是否要进行调整代码执行顺序这类优化措施。

### 历史和意义

内存模型允许编译器执行许多重要的优化。`编译器优化`，如程序中的循环融合移动语句，它可以影响潜在`共享变量的读写操作的顺序`。读取和写入顺序的变化可能导致`竞争条件`。如果没有内存模型，编译器通常不允许将此类优化应用于多线程程序，或者仅在特殊情况下。或者对于某些编译器来说，假设没有多线程执行（因此可以生成更好的优化代码），这可能导致与多线程不兼容的优化 - **这些通常会导致细微的错误，这些错误不会出现在早期测试中**.

因此， Java 等现代编程语言实现了内存模型。**内存模型指定了通过特殊的、定义良好的同步操作建立的同步屏障**，例如通过进入同步块或方法获取锁。内存模型规定，`只有在达到这种同步屏障时，才需要使其他线程可以看到对共享变量值的更改`。此外，竞争条件的整个概念是根据这些**内存屏障的操作顺序**定义的。[^1^](<https://en.wikipedia.org/wiki/Memory_model_(programming)#cite_note-1>)

然后，这些语义在应用优化时为优化编译器提供了更高的自由度：编译器**只需要确保同步屏障处的（可能共享的）变量的值在优化和未优化的代码中保证相同**。特别是，编译器假定在不包含同步屏障的代码块中重新排序语句是安全的。

内存模型领域的大多数研究都围绕着：

设计一个内存模型，允许**编译器优化的最大自由度**，同时仍然对无竞争和（也许更重要的）包含竞争的程序提供足够的保证。
证明关于这种内存模型的程序优化是正确的。
Java 内存模型是为流行的编程语言提供全面的线程内存模型的第一次尝试。[^2^](<https://en.wikipedia.org/wiki/Memory_model_(programming)#cite_note-2>)在确定**线程不能作为库安全地实现**之后，如果不对实现施加某些限制，特别是 C 和 C++ 标准（C99 和 C++03）缺乏必要的限制，[^3^](<https://en.wikipedia.org/wiki/Memory_model_(programming)#cite_note-3>) [^4^](<https://en.wikipedia.org/wiki/Memory_model_(programming)#cite_note-4>) C++ 线程小组委员会致力于研究合适的内存模型；2005 年提交 C 类工作文件 n1131 [^5^](<https://en.wikipedia.org/wiki/Memory_model_(programming)#cite_note-5>) 让 C 委员会加入他们的努力。在 2007 年 10 月的 Kona 会议上，提议的内存模型的最终修订版 **C++ n2429** [^6^](<https://en.wikipedia.org/wiki/Memory_model_(programming)#cite_note-6>) 被接受为 C++ 草案标准。[^7^](<https://en.wikipedia.org/wiki/Memory_model_(programming)#cite_note-7>) 内存模型随后被包含在下一个 C++ 和 C 标准 **C++11 和 C11** 中。[^8^](<https://en.wikipedia.org/wiki/Memory_model_(programming)#cite_note-8>) [^9^](<https://en.wikipedia.org/wiki/Memory_model_(programming)#cite_note-9>)

## c++ 内存模型

### 顺序一致性

多线程程序的执行可以这样看：
执行中的每个步骤都包括选择一个线程接下来执行，然后执行其执行的下一步。重复这个过程，直到整个程序终止。

因此，整个程序的有效执行可以被视为采取每个线程执行的所有步骤，并以某种方式将它们交错。每当访问一个对象（即变量、字段或数组元素）时，都会检索此交错序列存储的最后一个值作为该对象的值。

顺序一致性要求方法调用的执行行为具有某种顺序次序的执行结果，并且这种顺序执行的次序应该与程序次序保持一致。

考虑一个程序，它首先创建第二个线程，然后在两个线程中执行，其中 x 和 y 是合适整数类型的全局变量，初始化为零：

| 线程 1  | 线程 2  |
| ------- | ------- |
| x = 1;  | y = 1;  |
| r1 = y; | r2 = x; |

这可以通过以许多不同的方式交错来自两个线程的步骤来执行。以下是三种可能的执行方式，它们共同说明了 r1 和 r2 的所有可能最终值：

| 执行 1                   | 执行 2                   | 执行 3                   |
| ------------------------ | ------------------------ | ------------------------ |
| x = 1;                   | y = 1;                   | x = 1;                   |
| r1 = y;                  | r2 = x;                  | y = 1;                   |
| y = 1;                   | x = 1;                   | r1 = y;                  |
| r2 = x;                  | r1 = y;                  | r2 = x;                  |
| // 结果: r1 = 0; r2 = 1; | // 结果: r1 = 1; r2 = 0; | // 结果: r1 = 1; r2 = 1; |

还有一些关于多线程执行顺序的相关模型，可以参考 **多处理器的编程艺术**，虽然里面代码的实现和说明是 `java` 但是具有很多领域共通的知识.

考虑纯数据一致性的成本. 以及编译器需要做哪些额外的工作.

### 纯顺序一致性问题

例如，重新考虑上面的程序。大多数处理器在执行每个线程中的第二个语句之前实际上**并不等待初始分配完成**。初始分配只是将值 1 保存在**存储缓冲区**中，**等待**将其复制到内存中，但**对另一个处理器尚不可见**。如果两个线程要在不同的处理器上锁步执行，很可能 r1 和 r2 都为零，因为 x 和 y 的读取都 发生在写入对另一个线程可见之前。

保证顺序一致的执行成本太高了.

在这里如果保证顺序一致性执行, 还需要同步相关 cpu 以及主存.

同样，编译器通常会以**违反顺序一致性**的方式转换代码。例如，如果我们的初始示例是作为更大程序的一部分，编译器可能决定将 r2 = x 和 r1 = y "load" 操作中的一个或两个移动到各自线程的开头，以给它们更多时间在 r1 和 r2 中的值之前完成是需要的。使 load 提前发生，本质上相当于硬件延迟了存储；它可能再次导致两个 load 都读取为零。由于每个线程中的两个操作都涉及独立变量，因此编译器没有理由相信它们不可互换。这种编译器转换可以产生显着的性能改进，我们不想禁止它。

本质上，**硬件和编译器**都可以执行非常相似的优化，以**重新排序**其他线程所感知的内存引用。

事实上在进行多线程程序设计时，由于需要数据共享基本都会导致线程之间的相关资源竞争(发生在**同时写**) -> `数据竞争`

### 数据竞争和更严格的模型

数据竞争:
如果两个普通内存操作**访问相同的内存位置**（例如，变量或数组元素），并且其中至少有一个**写入该位置**， 我们就说这两个普通**内存操作发生冲突**。

如果存在顺序一致的执行 ，我们说一个程序**允许对一组特定的输入进行数据竞争**，即单个线程的**操作交错**，其中可以 "同时" 执行两个冲突的操作。出于我们的目的，两个这样的操作可以 "同时" 执行，如果它们在交错中彼此相邻发生，并且对应于不同的线程。如果对应于不同线程的两个普通内存操作在交错中相邻发生，我们知道它们同样可能以相反的顺序发生；如果某些操作强制执行该命令，它们将不得不出现在交错的中间。因此，此模型中的邻接实际上意味着**它们可能在具有真正并发性的模型中同时发生**。

**考虑仅在程序避免数据竞争时才保证顺序一致性**.

如何保证数据竞争时顺序一致性.

### locks

最常见的是，实际上并不是通过将**普通变量**转换为**同步变量**来防止数据竞争，而是通过**防止对普通变量的并发访问**。通常这是通过引入锁（有时称为互斥锁）来完成的，锁本身是由语言或支持库提供的特殊同步变量。

**互斥锁**对于操作系统而言一般都是提供的. 对于**底层汇编都有对应的支持**.

[x64 Assembly MultiThreading](https://www.youtube.com/watch?v=z3JqllRFUdE)

```cpp
void increment_c()
{
    // lockGuard
    l.lock();
    ++c;
    l.unlock();
}
```

多线程下可能的**指令重排**

```cpp
l.lock();
++c;
l.unlock();
l.lock();
++c;
l.unlock();
```

不期望的**指令重排**

```cpp
// 不合理的
l.lock();
l.lock();
++c;
++c;
l.unlock();
l.unlock();
```

对于 `lock` 编译器和操作系统都需要考虑**特殊**处理.

难道多线程只有 **数据竞态** 这种问题吗?

### 我们是否丢失了一些重要的东西

乍一看，对**无数据竞争程序的顺序一致性的限制**似乎对多线程编程来说是一个**不必要**的复杂化，这当然已经是一个**足够困难**的问题了。但是，还有**其他重要的原因**要去阻止数据竞争。事实上，这种互斥方式的限制几乎只影响我们真正想要阻止的程序。

考虑一个像我们最初的例子这样的程序，其中 x 和 y 被解释为普通的整数变量。假设我们期望它产生我们之前列出的三种可能的**预期结果**之一。这隐含地**依赖于某些操作的原子性**。在我们上面的解释中，我们假设像 x = 1 这样的赋值是 "一次性" 发生的。在这种特殊情况下，这可能是合理的。但是如果赋值是 **x = 1000000** 呢？如果 **x 是 16 位处理器上的 32 位整数**，这可能已被转换为两个硬件 "load" 指令，分别用于常量 1000000 的**上半部分**和**下半部分**. 因此，另一个线程不仅能够看到 0 和 1000000 的 x 值；它还可能会看到 **"中间"** 值，**其中二进制表示中的一半位已更新**。在这种情况下，它可能还会看到 **983040** 或 **16960**。

这个问题在实际程序中以许多其他形式出现。在 C 或 C++ 程序中，**单个赋值 w = z 可以复制整个结构对象**。在所有当前的硬件上，**这通常会被实现为组件的多个分配**，即使在 64 位机器上也是如此。但是同样，在另一个线程中同时读取 w 的程序将取决于对 w 更新的 "粒度" ，即**由硬件指令以原子方式（不可分割地）更新的片段的大小**。

如果我们避免数据竞争，而是将我们希望通过 `lock()/unlock()` 对 **不可分割** 地执行的操作封装起来，确保对给定共享变量的访问始终受到同一个锁的保护，我们就避免了所有这些问题. 我们已经明确了**不可分割动作的粒度**。

```cpp
// lock
tmp = c;
++tmp;
c = tmp;
// unlock
// 其他线程如果在这个过程中读 tmp，是否会出现问题?
```

如果我们**交错**由**两个不同线程**执行的两个这样的计数器递增操作，我们可以得到

```cpp
// c 作为同步变量
tmp1 = c; // 读取 n
tmp2 = c; // 读取 n
++tmp1;
++tmp2;
c = tmp1; // 写入 n + 1
c = tmp2; // 写入 n + 1
// 有效地丢失了更新之一
```

在这种情况下，将 c 转换为**同步变量**的替代解决方案可能还不够。即使它是一个同步变量，**增量也可能由对 c 的两次原子访问组成** ，而不是**一次读取和写入 c**，因此允许与上面相同的交错。

**同步变量使得从不同线程同时访问变量变得安全**，并且要求实现表现得好像基本步骤只是交错的一样。但是这些**基本步骤的大小**是一个不同的问题。在增量操作的情况下，不同的编程语言以不同的方式解决它。

在更复杂、更典型的情况下，对多个内存位置的操作**必须不可分割**地执行。这是真的，例如，如果一个线程将元素添加到容器数据结构，而另一个线程检查或删除它们。在这种情况下，到目前为止，**最简单的方法是用锁保护数据结构**。

在所有这些情况下，**仅仅保证原始程序的顺序一致性是不够的**；程序员必须消除数据竞争，有时以非平凡(同步变量)的方式，以确保正确执行。在此过程中，**程序员必须明确描述必须不可分割地执行的代码部分——这是编写并行程序的重要部分**。

对于一个**并发数据结构**而言，**数据竞争的粒度**对**并发操作**有着非常重要的影响.

### 避免更高抽象级别的数据竞争

我们可能使用实现集合的库，我们的程序可能包含从集合中插入和删除元素的调用，并检查集合是否包含特定元素。如何在该级别防止数据竞争？

锁定粒度，锁定范围，锁定频率

这里的锁定是泛义上的锁定，实际上等同于**同步**. **实现上可能是锁, 也可能是原子语句**.

### 一些 Java 细节

由于 Java 旨在支持作为受信任应用程序的一部分运行的不受信任代码，因此它必须限制不受信任代码中的数据竞争造成的损害。因此，它**不能允许数据竞争的任意行为**。因此，Java 语言规范包含一组 **复杂的规则**，这些规则定义了**线程间共享对象的行为**，包括存在数据竞争时的行为。这些规则的后果甚至对专家来说都是令人惊讶的。但是，它们确实**保证了无数据竞争程序的顺序一致性**，**这是一个更容易编程的模型**。

数据竞争的 Java 定义使用我们上面提到的替代定义样式。必须通过从**同一线程执行它们或通过引入强制线程之间的排序的同步变量来防止同时发生冲突操作**。如果使用这些机制对它们进行排序，则可以说**一个内存操作在另一个内存操作之前发生**，因此在交织中不能同时发生。这基本上等同于我们的定义。

在几乎所有情况下，Java 程序的编写都应该简单地避免数据竞争，并**依赖于顺序一致性**。实际上只有三种情况对数据竞争的额外保证很重要：

-   对于必须保证它们的**编译器编写者**。
-   对于需要限制不受信任的 **"沙盒" 代码可能造成的损害的特别安全敏感代码的作者**。
-   对于对**性能极为敏感**的代码的非常老练的作者，**使用同步变量的额外成本太高**。一些这样的代码嵌入在 java.util.concurrent 库中，但我们预计很少有其他程序员编写它。

Java 以一种**不同寻常**的方式提供锁：**每个 Java 对象都可以充当锁**，即它在逻辑上具有关联的锁。Java 没有提供显式的 lock()和 unlock()操作，而是提供了**同步块（和方法）来获取和释放锁**，并在执行指定的代码块时持有它：

```java
synchronized (object_used_as_lock) {
  // code to be executed with lock held
}
```

尽管最近的 Java 版本也提供了显式锁定操作（在 java.util.concurrent.locks 中），但**同步块具有很大的优势，即锁沿着块外的所有路径释放，包括在抛出异常时，从而消除了一个常见的错误的来源**。

正如我们上面提到的，**同步变量，或者更准确地说是对象字段**，通常使用 **volatile** 关键字声明。由于这不是一个单独的类型，它有一些可能令人惊讶的后果：

-   **数组元素不能用于同步**，因为无法将数组元素声明为 volatile。
-   正如我们之前所暗示的， **volatile** 仅影响单个内存访问。如果 i 被声明为 volatile int i，则 ++i 由**两个独立的不可分割的内存访问组成**，即作为一个整体的增量不是不可分割的。

[java.util.concurrent.atomic](http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/atomic/package-summary.html) 包提供了一些 **"原子" 类型**，可以用来规避这两种情况。
[Java.util.concurrent](http://gee.cs.oswego.edu/dl/jsr166/dist/docs/java/util/concurrent/package-summary.html) 提供了许多其他工具来支持多线程程序，包括用于在线程之间同步或通信的大量组件库。

看一下 **C++0x** 的一些细节.

### 一些 C++0x 细节

C++0x 包含对语言中线程的显式支持。通过创建 `std::thread` 类的实例，向构造函数传递要执行的函数或可调用对象来创建线程。

由于 C++ 的设计目的**不是针对不受信任的代码提供保护**，因此在发生数据竞争时它无法保证任何事情。**任何允许数据竞争的程序**都会产生 **"未定义的行为"**。

在没有数据竞争的情况下，如果不使用某些低级库设施（见下文），它再次**提供了顺序一致性**。与 Java 一样，这在官方语言描述中也不是很明显。在这种情况下，语言描述变得更加复杂不是因为数据竞争的处理，而是那些**低级的库设施**。

可以通过构造互斥体（通常为 `std::mutex` 类型）来获取锁，然后通过将其传递给 `std::lock_guard` 对象的构造函数来获取它。 `lock_guard` 析构函数将释放锁，确保与 Java 的情况一样，`即使抛出异常也能释放它`。因此，获取锁的典型代码如下所示：

```cpp
#include <mutex>
std::mutex mtx; // 锁; 由多个线程共享
// ...
{
    std::lock_guard _(mtx);
    ++c;
}
```

在 C++0x 中，**整数同步变量** i 可能被声明为

```cpp
atomic<int> i;
```

**同步变量**与**普通变量**的类型不同，因此可以提供不同的成员函数实现。如果 i 声明为如上，则实现**确保并发访问的顺序一致行为**，但它也确保 ++i 将原子递增 i，作为单个不可分割的操作。
(**Volatile** 也存在于 C++ 中。由于历史原因，它在那里**意味着其他东西**。)

目前看来，其他一些环境也将遵循 C++0x 模型。 目前的迹象表明，下一个 C 标准将遵循类似于 C++0x 的方法。 **OpenMP** 似乎也在朝着类似的解决方案发展。

### 内存位置和 C/C++ 位域

我们对**冲突访问的定义以及对数据竞争的间接定义是指同时访问 "内存位置"** 。我们看到，**在 Java 中，内存位置只是一个标量变量、对象字段或数组元素，即程序可以单独更新的最小单元**。考虑以下示例，其中 x 是一个包含两个小整数（例如 C 中的 char）字段 a 和 b 的结构：

| 线程 1  | 线程 2  |
| ------- | ------- |
| xa = 1; | xb = 1; |

这里对 a 和 b 字段的两个**赋值通常不冲突**，因此不存在**可能的数据竞争**。

C++0x（可能还有未来的 C 版本）必须对此规则做出一个例外。它们允许结构包含通常不包含整数字节的位域。**主流硬件不允许在不覆盖相邻字段的情况下有效更新这些字段**。如果上例中的 a 和 b 是小的位域，线程 1 **通常会被编译**为

```cpp
tmp = x;
tmp.a = 1;
x = tmp;
```

即**整个结构将被读取和写回**。这确实与线程 2 分配冲突，特别是因为它会被类似地翻译。因此，**C++0x 将连续位域序列中的所有（非零长度）位域视为单个内存位置的一部分**；对一个人的分配与对其他任何人的分配冲突。**这种连续的位域不应由不同的线程同时更新**。通常**这意味着它们应该受到单个锁的保护**。

### 一些 pthread 细节

不幸的是，目前没有可用的 C++0x 实现。当前希望在 C 或 C++ 中使用线程的任何人**都将使用单线程语言**，**以及允许创建线程和提供锁定操作等的库**。
两个最常见的线程库接口是 `Microsoft` 的 `Windows` 线程和 `Posix` 线程。我们专注于后者，因为它是由一个有十年历史的国际标准描述的。

线程是通过调用 `pthread_create()` 和新线程要执行的函数来创建的。

这种`基于附加线程库的整个方法`并不完全令人满意。**如果没有在线程上下文中真正定义编程语言，就不清楚哪些编译器转换是合法的，因此也不清楚允许程序员假设什么**。

然而，Posix 标准的意图显然接近于我们在此描述的 "**无数据竞争程序的顺序一致性**"。特别是，它要求 "**应用程序应确保多个控制线程（线程或进程）对任何内存位置的访问受到限制，这样任何控制线程都不能读取或修改内存位置，而另一个控制线程可以修改它**。" 因此，任何具有数据竞争的应用程序都具有未定义的行为，如在 C++0x 中。

这个数据竞争的定义 存在一些不确定性和模糊性：

-   目前尚不清楚 Posix 的同时访问概念是否与我们的相同。正如我们将在下一节中看到的，声称**符合 Posix 的编译器有时会使用稍微不同的解释**。
    尽管如此，我们仍将继续假设我们对数据竞争的定义。实际编译器**明显偏离**这一点的情况很少引入真正的问题。而且我们一直**无法设计出有用的编程规则**来考虑这些情况。我们认为，从长远来看，**修复有问题的编译器以强制执行类似 C++0x 的规则既是唯一可接受的选择，也是当前趋势**。
-   Posix 故意未定义 "**内存位置**" 的含义。特别是，它显然允许我们 上面的结构示例中的两个线程相互干扰。幸运的是，很少有实现充分利用这种自由。**当前的 C 和 C++ 实现通常会生成在更新位字段时读取和重写相邻小整数字段的代码**。例如，在 a 中读取和重写 a 字段 是很常见的。

```cpp
struct {char a; int b:5; int c:11; char d;}
```

结构，当 b 或 c 字段更新时。因此，**如果位域序列可能与相邻的非位域同时访问，则应该将它们分离到一个单独的子结构中**。例如，上面可以重写为

```cpp
struct {char a; struct {int b:5; int c:11;} bc; char d;}
```

这通常既可以**避免问题**，又可以增加结构的大小。

`Posix` 标准的目的是保证**不允许数据竞争的应用程序的顺序一致性**，至少在没有从线程库中的函数返回错误的情况下。

由于 pthread 被设计为 C 的附加库，因此它们使用函数调用语法来获取和释放锁。典型的代码序列会将锁声明为

```cpp
#include <pthread.h>
pthread_mutex_t mtx = PTHREAD_MUTEX_INITIALIZER;
```

然后将其用作

```cpp
pthread_mutex_lock(&mtx);
++c;
pthread_mutex_unlock(&mtx);
```

不幸的是，**Posix 和底层语言都不支持将整数变量转换为同步变量的机制**。当前的平台通常确实支持既不是非常明确定义也不符合我们的 "**无数据竞争程序的顺序一致性**" 观点的近似值。

在某些平台上，**C 或 C++ volatile 声明具有有时使它们可用于线程通信的特性**。但与 Java 不同的是，C 的 volatile 最初并不是为此而设计的，而且很 明显，**扩展它以跨平台可靠地执行此功能是不可行的**。

`Gcc` 和 `Microsoft` 编译器支持原子操作，其名称分别以 " **sync\_ " 和 " Interlocked "开头，以原子更新共享变量。许多其他编译器提供类似或相同的支持。两者都没有明确相应的原子读取或加载操作，因此无法提供可移植的顺序一致性保证。其中一些原语还以其他方式违反了我们的保证。将这些原语与（可能是 `volatile` 的）load 结合起来，然后加上诸如 **sync_synchronize()之类的内存栅栏，通常应该会产生预期的效果。（注意，如果一个普通的，甚至是易变的 store 用于分配这样一个共享同步变量，它可能需要在前面和后面加上一个栅栏，以确保我们介绍性示例的顺序一致性和正确性

**强烈建议在 C++0x 风格的原子变量可用时立即使用它们**。**libatomic_ops** 包可能会 提供另一个权宜之计。

### 更多示例

-   没有数据竞争
    | 线程 1 | 线程 2 |
    | ------------------ | ------ |
    | if (x != 0) y = 1; | y = 2; |

-   没有数据竞争
    | 线程 1 | 线程 2 |
    | ------------------ | ------ |
    | if (x != 0) y = 1; | if (y != 0) x = 1; |

-   有数据竞争

    | 线程 1                  | 线程 2 |
    | ----------------------- | ------ |
    | y = ((x != 0) ? 1 : y); | y = 2; |

尽管线程 1 的两个程序在没有线程的情况下是等价的，但它们在有线程的情况下是不等价的。在新版本中，y 被无条件分配给。特别是，**它可以在线程 2 执行的同时写入**。像往常一样，**这种数据竞争表明可能存在问题**。由于线程 1 的代码通常不会被不可分割地执行，因此该程序可以执行为，例如，

```cpp
tmp = ((x != 0)? 1 : y); // tmp = 0
y = 2;
y = tmp; // y = 0
```

这可能是一个**意想不到**的结果，在本节的初始示例中是不可能的。因此，不允许编译器像我们在这里建议的那样转换代码，尽管硬件条件移动指令通常会使最后一个版本更快，或者它可能允许向量化包含循环。**如果打算使用更快的版本，则必须显式编写它，或者编译器必须能够确定所涉及的变量不是共享的**。

一些更**常见的编译器优化也可能引入数据竞争**。考虑一个循环（使用 C 语法编写）计算列表中负元素的数量，其中变量 count 是全局或静态类成员：

```cpp
void count_neg(T *q) {
  for (T*p = q; p != 0; p = p->next;) {
    if (p->data < 0) ++count;
  }
}
```

如果第二个线程可以 在此循环更新 计数时访问计数，则此代码清楚地引入了数据竞争。
**编译器可能会尝试将计数器临时保存在本地（寄存器）变量中**，并将代码转换 为：

```cpp
// 可能会引发数据竞赛
void count_neg(T *q) {
  int local_count = count;

  for (p = q; p != 0; p = p->next;) {
    if (p->data < 0) ++local_count;
  }
  count = local_count;
}
```

将 pos_list 设置为包含数据字段 1 和 2 的列表，并将 count 声明为初始化为零的全局变量，然后执行:

| 线程 1               | 线程 2    |
| -------------------- | --------- |
| count_neg(pos_list); | count ++; |

**该程序的原始版本不包含数据竞争**，因为 pos_list 不包含负元素，因此 线程 1 既不读取也不写入计数变量。

（有些人认为这种数据竞争的定义是不必要的，因为它是根据特定的执行来表述的，因此考虑到传递给函数的特定参数。但是，**特别是对于带有指针参数的实际程序，这是唯一有意义的定义**。**否则任何通过指针写入的函数都会引入基本上所有内容的数据竞争**。）

转换后的程序无条件写入计数，因此引入了数据竞争。

（虽然这种转换在 `Java` 和 `C++0x` 中显然是非法的，但它在 `Posix` 中的状态尚不清楚，并且它通常由许多当前的（2008）C 编译器执行。）

请注意，至少在没有异常的情况下，可以将代码转换为

```cpp
void count_neg(T *q) {
  int local_count = 0;

  for (p = q; p != 0; p = p -> next;) {
    if (p -> data < 0) ++local_count;
  }
  if (local_count != 0) count += local_count;
}
```

### 关于同步操作实现的说明

不幸的是，大多数硬件并没有**区分数据和同步操作**，并**为并发内存访问提供语义**，这与我们在这里提出的完全不同，并且从一个硬件平台到另一个硬件平台差异很大。特别是对于那些对硬件内存模型有一定了解的读者，我们简要**建议如何将普通的内存操作和同步访问编译到假设的机器上**（与最近的 ARM 处理器有些相似，但 Itanium 汇编器语法）。
我们强调这个描述非常不精确，对于编译器编写者来说是不够的，并且不是我们对编程模型的描述的一部分。将其包含在此处只是希望我们可以帮助协调本文其余部分的介绍与读者对该主题的先入之见。

**现代处理器通常依靠高速缓存或仅使用高速缓存来提供对频繁访问的内存位置的快速访问，方法是将这些位置的本地副本保存在速度更快的内存中，通常与每个处理器相关联**。处理器不是直接访问主内存，而是确保内存右侧部分的副本在其缓存中，然后访问缓存的副本。有时，例如当缓存空间不足时，一些缓存内容会被写回主存。

尽管**这些缓存经常被归咎于硬件级别的复杂内存排序模型**，但这种指责有些错位。**硬件使用缓存一致性协议**，例如 MESI 协议来保持所有缓存的内容一致。通常，这是通过确保只有当其他处理器在其缓存中没有该位置的副本时才能更新缓存中的位置。因此在这个级别上，所有处理器共享一致的内存视图，并且**所有内存操作通常几乎就像来自不同线程的操作是交错的一样执行**。（有关内存系统和缓存的更全面的描述，请参见 Ulrich Drepper，“What Every Programmer Should Know About Memory”。）

但是，处理器通常会执行**其他类型的优化**，这些优化具有**重新排序内存访问的效果**，因此**普通的内存访问不再足以实现同步操作**。例如，处理器通常不需要等待写入完成后再进行后续计算，因此可以缓冲不完整的写入并继续。**当后续加载（来自不同地址）完成而写入仍在缓冲时，重新排序可以变得可见**。如果 示例中的 x 和 y 是同步变量，这可能会导致类似于我们的介绍性示例的错误结果。（有关其他此类优化，请参阅 Adve 和 Gharachorloo，共享内存一致性模型：教程，IEEE 计算机，1995 年。）

为了解决这个问题，处理器通常还提供**内存栅栏**指令。这些用作处理器的标记，以**禁止对特定指令进行某些优化**。对于我们假设的硬件，我们将考虑一个通用栅栏，它**确保在栅栏之前出现的内存操作在随后出现的任何操作之前对所有处理器都是可见的**。

我们的通用栅栏的一个简单实现是处理器在栅栏上阻塞，直到所有先前的指令都完成并且对整个内存系统可见。除非发生这种情况，否则不允许超出围栏的指令继续进行。实际上，**当前的处理器提供了广泛的栅栏，可以确保仅在操作子集之间进行排序，甚至需要对多个处理器的操作进行推理以确定它们的语义**——这里，我们只考虑上面描述的最简单的栅栏。

为了使这一点更精确，我们假设我们的说明性硬件架构具有以下特征：

-   它具有加载和存储指令，具有合适的数据大小。我们将为将位置 x 的内容加载到寄存器 ri 的指令编写 **ld ri = [x]**。我们将编写 **st [x] = ri** 将寄存器 ri 的内容存储到位置 x 中。
-   **普通加载和存储要求访问的数据在内存中适当对齐**，例如 4 字节值存储在 4 字节边界上。**作为回报，它们被不可分割地执行**，即它们在其他线程看来已经被完全执行，或者根本没有被执行。（**不需要这种对齐的架构通常不能保证这种原子性，因为单个加载或存储指令可能需要对物理内存的多次访问**。）
-   加载和存储指令可以由硬件任意重新排序，因为它们可能以任意顺序对其他处理器或线程可见。
-   **当存储指令的结果对另一个处理器可见时，它对所有处理器都可见**。（这通常适用于类似于我们上面描述的内存系统，并且由例如 X86 架构规范保证。例如，如果支持两个线程的核心上的另一个线程可以看到世界其他地方之前的写缓冲区。）
-   处理器支持栅栏指令，该指令等待之前的内存操作完成，如上所述。
-   处理器支持 **xchg ri, [x]** 指令以原子方式交换寄存器 ri 和位置 x 中的值。尽管这种交换是不可分割地发生的，但它并没有相对于其他操作进行排序。
    这个描述太草率了，不能作为实际实现的基础，但它希望能传达正确的直觉。
    请注意，**通常围栏指令和可能的 xchg 指令比普通的加载和存储要昂贵得多**。它必须等待先前未决的内存操作的结果, 通常指令相隔并不远。

在这种机器上的典型实现会生成如下代码，同时还要**确保编译器本身不会执行违反顺序一致性的代码重新排序**。这些是一般性的翻译，编译器在特定情况下可能会做得更好：

#### 简单的 loads 和 stores

**普通的内存访问被编译为普通的加载和存储指令**。这在实际架构中通常是必不可少的，因为相对于单线程代码，其他任何事情都会涉及显着的减速。

正如我们在上面的一些示例 中指出的那样， **编译器不要将 store 引入原始源中可能未修改的内存位置是至关重要的**，即使这些存储存储了刚刚从同一位置读取的值。引入这样的存储通常会引入可能导致错误结果的数据竞争。

更微妙的一点是，**如果不使用结果，编译器可能会并且经常会引入引入数据竞争的 load**。例如，如果某个变量的值在一段时间内被重复使用-loop，通常只需提前一次将其加载到寄存器中，即使循环体有时根本不执行。这有时会引入数据竞争。因此，如果结果是另一个 C++ 程序，那么以这种方式转换 C++ 程序是不可接受的。然而，编译器通常会生成机器代码，这些代码确实为具有数据竞争的程序提供了明确定义的含义。因此，这样的转换，在通往机器代码的路上，通常会保留意义，并且是可以接受的。（此规则的一个例外可能是当前假设但非常理想的检测数据竞争的机器。）

受限于对新引入的存储的限制，**以在单线程程序中正确的方式重新排序普通加载和存储不会违反无数据竞争程序的顺序一致性，只要这些操作不跨同步操作移动. 一些经过同步操作的动作也可以，但更复杂的规则适用于那里**。对于像 Java 这样为具有竞争的程序提供语义保证的语言，实际的转换规则更加复杂。

#### 同步 loads

**同步负载被编译为普通负载，后跟围栏**。要了解为什么这是必要的，请考虑首先等待设置共享同步变量的代码，然后访问一些共享数据，如我们之前的 惰性初始化示例：

```cpp
declare x_init as synchronization variable;
while (!x_init);
// -----
access x which was previously initialized by another thread;
```

如果在第一次访问 x 之后可以以某种方式 最终读取 x_init ，则此代码可能会错误地看到 x 的未初始化值。在**同步加载之后插入的栅栏指令，在这种情况下是 x_init，可以防止这种重新排序，并确保 x 仅在设置 x_init 后才真正被访问**。

#### 同步 stores

**同步存储被实现为存储指令，在栅栏指令之前和之后**。

要了解为什么需要前面的栅栏，请考虑 前面示例中初始化 x 的线程。它被写成

```cpp
x = initial value;
// -----
x_init = true;
// -----
```

如果此线程中的两个分配可能变得乱序可见，则读取线程可能会在 x 正确初始化之前再次看到 x_init 设置。**分配给同步变量 x_init 之前的栅栏阻止了这种重新排序**。

在此示例中， **x_init 后面的栅栏不是必需的，但在一般情况下是必需的，以防止同步存储在后续同步加载时重新排序**。要看到这一点，请重新检查我们的介绍性示例，将变量 x 和 y 解释 为同步变量：

| 线程 1  | 线程 2  |
| ------- | ------- |
| x = 1;  | y = 1;  |
| r1 = y; | r2 = x; |

```cpp
// 1
x = 1;
// ----- store 之后
// ----- load 之前
r1 = y;
// 2
y = 1;
// ----- store 之后
// ----- load 之前
r2 = x;
```

**存储之前的栅栏和加载之后的栅栏都不能防止每个线程中的分配被重新排序**，这可能导致非顺序一致的 r1 = r2 = 0 结果。**为了防止这种重新排序，我们需要在同步存储之后或同步加载之前设置一个栅栏。由于加载往往更频繁，我们通常会选择前一种约定**。

#### locks

一个简单的自旋锁可以表示为一个变量 l 持有 0（未锁定）或 1（锁定）。锁定操作可以通过设置一个寄存器来实现，比如 r1 为 1，然后重复执行 `xchg r1, [l]` 直到 r1 变为 0，这表明我们的线程**设法将 l 更改为它的锁定状态**。**这之后需要一个栅栏指令，以确保在实际获取锁之前，旨在执行互斥的操作不会变得可见**。（真正的实现通常会避免重复的 xchg 等待锁定时的操作，因为它们会在处理器缓存之间创建大量不必要的通信。）
上面的自旋锁可以通过使用普通的存储指令将 l 重置为 0 来释放。这次我们需要一个前导栅栏来防止操作在 unlock()操作后变得可见而 "逃逸" 关键部分。

请注意，lock() / unlock()操作每个只需要一个栅栏，而不是像同步存储操作那样需要两个。这依赖于 一个论点，即在没有数据竞争的情况下无法观察到差异，这反过来又对如何访问锁做出了一些假设，如下一节的“非阻塞锁获取”中所述。
许多真实机器架构允许硬件执行的内存操作重新排序比我们在这里假设的要少。例如，在传统的“X86”机器上，如果同步存储是使用 xchg 指令实现的，则不需要显式围栏，这可能是应该的。另外，同步加载可以用普通的加载指令来实现，简单的锁可以用普通的存储指令来释放

### 遗漏和扩展

在这里，我们只关注与跨多个线程简单使用共享变量有关的问题。这些是任何多线程程序的作者都应该熟悉的最基本的问题。我们省略了线程实现通常提供的一些其他功能。尽管使用频率较低，但它们对于您的应用程序可能仍然是必不可少的：

#### 其他锁类型

大多数环境提供可以多次持有的“可重入”锁，但只能由单个线程持有。例如，这是由 Java 同步 块获取的“锁”的行为。提供读写器锁也很常见，它可以由多个“读取器”线程持有，但只能由单个“写入器”持有。

#### 条件变量等

条件变量是让线程等待直到满足特定条件（例如，直到共享队列非空）的最常见机制。这些提供了一个 wait()调用来释放和重新获取一个锁，在这之间暂停线程一段时间，最多直到它被另一个线程唤醒（"通知" 或发出信号）。条件变量很容易在程序中引入死锁，如果一个线程没有被可靠地唤醒。因此应该谨慎使用它们。但是如果我们唯一关心的是我们的程序不会产生不正确（而不是 no）的答案，那么 wait( cv, lock )调用的行为就像 unlock(锁）；锁（锁） 序列。因此，新问题与本文非常正交。

#### 非阻塞锁获取

大多数语言或线程库都提供了 trylock() 原语，该原语要么获取锁，如 lock()，要么返回错误指示。与 lock()不同，它从不等待。这很容易适应我们的模型，只要我们允许 trylock() 潜在地返回错误指示，即使锁可用，或者至少对我们的代码进行推理，就好像这可能发生一样。出于 微妙的原因，需要这个假设来禁止程序，否则这些程序可能会看穿实现精心提供的顺序一致性错觉。类似的观察适用于可能超时的锁获取调用。在实践中，这只不允许滥用的代码 trylock()，并且应该使用其他原语。（另一种选择是在许多架构上更昂贵的锁实现。经验表明，无论标准是否需要它们，都不会使用这种实现。）

#### 从顺序一致性中"逃脱"

许多语言允许对显式违反顺序一致性的同步变量进行某些访问，即使对于不包含数据竞争的程序也是如此。在某些平台上，使用这些可能会显着提高性能，但代价是更复杂的编程模型，这里不讨论。例如， java.util.concurrent.atomic 的 lazySet() (Java 6 +) 和 weakCompareAndSet()允许实现以与顺序一致性不一致的方式重新排序操作。C++0x 原子 对象支持具有显式内存排序约束参数的操作（例如 memory_order_relaxed），其中大多数再次与顺序一致性不一致。

## c++ 内存模型标准

<!-- ### 草案

-  -->

### 标准

C++0x（很可能是真正的 C+11）国际标准最近获得批准。它包含一个精心定义的内存模型（主要在 1.10 中，在第 29 节中有一些部分）、一个原子操作库（第 29 节）和一个线程 API（第 30 节）.

#### 1.10 Multi-threaded executions and data races

1. 执行线程（也称为线程）是程序中的单个控制流，包括特定顶级函数的初始调用，并递归地包括线程随后执行的每个函数调用。 [注意：当一个线程创建另一个线程时，对新线程顶层函数的初始调用由新线程执行，而不是由创建线程执行。 — 尾注] 程序中的每个线程都可能访问程序中的每个对象和函数。10 在托管实现下，C++ 程序可以同时运行多个线程。每个线程的执行按照本标准其余部分的定义进行。整个程序的执行包括其所有线程的执行。 [注意：通常可以将执行视为所有线程的交错。但是，某些种类的原子操作，例如，允许执行与简单的交错不一致，如下所述。 — 尾注] 在独立实现下，程序是否可以有多个执行线程由实现定义.
> A thread of execution (also known as a thread) is a single flow of control within a program, including the initial invocation of a specific top-level function, and recursively including every function invocation subsequently executed by the thread. [ Note: When one thread creates another, the initial call to the top-level function of the new thread is executed by the new thread, not by the creating thread. — end note ] Every thread in a program can potentially access every object and function in a program.10 Under a hosted implementation, a C++ program can have more than one thread running concurrently. The execution of each thread proceeds as defined by the remainder of this standard. The execution of the entire program consists of an execution of all of its threads. [ Note: Usually the execution can be viewed as an interleaving of all its threads. However, some kinds of atomic operations, for example, allow executions inconsistent with a simple interleaving, as described below. — end note ] Under a freestanding implementation, it is implementation-defined whether a program can have more than one thread of execution.

2. 实现应该确保所有未阻塞的线程最终都会取得进展。 [ 注意：标准库函数可能会静默阻塞 I/O 或锁定。执行环境中的因素，包括外部强加的线程优先级，可能会阻止实现对前进进度做出某些保证。 ——尾注]
> Implementations should ensure that all unblocked threads eventually make progress. [ Note: Standard library functions may silently block on I/O or locks. Factors in the execution environment, including externally-imposed thread priorities, may prevent an implementation from making certain guarantees of forward progress. — end note ]

3. 根据以下规则，线程 T 在特定点可见的对象的值是对象的初始值、由 T 分配给对象的值或由另一个线程分配给对象的值。 [注意：在某些情况下，可能会出现未定义的行为。本节的大部分内容是出于支持具有明确和详细可见性约束的原子操作的愿望。但是，它也隐含地支持更受限制的程序的更简单视图。 ——尾注]
> The value of an object visible to a thread T at a particular point is the initial value of the object, a value assigned to the object by T , or a value assigned to the object by another thread, according to the rules below. [ Note: In some cases, there may instead be undefined behavior. Much of this section is motivated by the desire to support atomic operations with explicit and detailed visibility constraints. However, it also implicitly supports a simpler view for more restricted programs. — end note ]

4. 如果其中一个修改了内存位置 1.7 而另一个访问或修改了相同的内存位置，则两个表达式求值会发生冲突.
> Two expression evaluations conflict if one of them modifies a memory location1.7 and the other one accesses or modifies the same memory location.

5. 该库定义了许多原子操作（第 29 条）和互斥体上的操作（第 30 条），它们被特别标识​​为同步操作。这些操作在使一个线程中的分配对另一个线程可见方面起着特殊的作用。一个或多个内存位置上的同步操作是消耗操作、获取操作、释放操作或获取和释放操作。没有关联内存位置的同步操作是栅栏，可以是获取栅栏、释放栅栏或获取和释放栅栏。此外，还有非同步操作的宽松原子操作，以及具有特殊特性的原子读-修改-写操作。 [注意：例如，获取互斥锁的调用将对包含互斥锁的位置执行获取操作。相应地，释放相同互斥锁的调用将对这些相同位置执行释放操作。非正式地，在 A 上执行释放操作会强制其他内存位置上的先前副作用对稍后在 A 上执行消耗或获取操作的其他线程可见。“放松”原子操作不是同步操作，即使像同步操作一样，他们不能为数据竞赛做出贡献。 ——尾注]
> The library defines a number of atomic operations (Clause 29) and operations on mutexes (Clause 30) that are specially identified as synchronization operations. These operations play a special role in making assignments in one thread visible to another. A synchronization operation on one or more memory locations is either a consume operation, an acquire operation, a release operation, or both an acquire and release operation. A synchronization operation without an associated memory location is a fence and can be either an acquire fence, a release fence, or both an acquire and release fence. In addition, there are relaxed atomic operations, which are not synchronization operations, and atomic read-modify-write operations, which have special characteristics. [ Note: For example, a call that acquires a mutex will perform an acquire operation on the locations comprising the mutex. Correspondingly, a call that releases the same mutex will perform a release operation on those same locations. Informally, performing a release operation on A forces prior side effects on other memory locations to become visible to other threads that later perform a consume or an acquire operation on A. “Relaxed” atomic operations are not synchronization operations even though, like synchronization operations, they cannot contribute to data races. — end note ]

6. 对特定原子对象 M 的所有修改都以某个特定的总顺序发生，称为 M 的修改顺序。如果 A 和 B 是原子对象 M 的修改，并且 A 发生在（如下定义）B 之前，则 A 应按照 M 的修改顺序在 B 之前，定义如下。 [注：这表明修改命令必须尊重 "发生在之前" 的关系。 — end note ] [ 注意：每个原子对象都有一个单独的顺序。不要求这些可以组合成所有对象的单个总订单。一般来说，这是不可能的，因为不同的线程可能会以不一致的顺序观察对不同对象的修改。 ——尾注]
> All modifications to a particular atomic object M occur in some particular total order, called the modification order of M . If A and B are modifications of an atomic object M and A happens before (as defined below) B, then A shall precede B in the modification order of M , which is defined below. [ Note: This states that the modification orders must respect the “happens before” relationship. — end note ] [ Note: There is a separate order for each atomic object. There is no requirement that these can be combined into a single total order for all objects. In general this will be impossible since different threads may observe modifications to different objects in inconsistent orders. — end note ]

7. 原子对象 M 上的释放操作 A 的释放序列是 M 的修改顺序中副作用的最大连续子序列，其中第一个操作是 A，并且每个后续操作 - 由相同的线程执行执行A，或者是原子读-修改-写操作
> A release sequence from a release operation A on an atomic object M is a maximal contiguous sub-sequence of side effects in the modification order of M , where the first operation is A, and every subsequent operation -- is performed by the same thread that performed A, or is an atomic read-modify-write operation

8. 某些库调用与另一个线程执行的其他库调用同步。例如，原子存储释放与从存储（29.3）获取其值的加载获取同步。 [注：除非在指定的情况下，读取后面的值不一定能确保可见性，如下所述.
   这样的要求有时会干扰有效的实施。 — end note ] [ 注意：同步操作的规范定义了一个人何时读取另一个人写入的值。对于原子对象，定义很明确。给定互斥体上的所有操作都以单个总顺序发生。每次互斥量获取都会“读取上一次互斥量释放所写入的值”。 ——尾注]
> Certain library calls synchronize with other library calls performed by another thread. For example, an atomic store-release synchronizes with a load-acquire that takes its value from the store (29.3). [ Note: Except in the specified cases, reading a later value does not necessarily ensure visibility as described below.
   Such a requirement would sometimes interfere with efficient implementation. — end note ] [ Note: The specifications of the synchronization operations define when one reads the value written by another. For atomic objects, the definition is clear. All operations on a given mutex occur in a single total order. Each mutex acquisition “reads the value written” by the last mutex release. — end note ]

9. 评估 A 携带对评估 B 的依赖，如果
   — A 的值用作 B 的操作数，除非:
   — B 是对 std::kill_dependency (29.3) 的任何特化的调用，或
   — A 是内置逻辑 AND（&&，参见 5.14）或逻辑 OR（||，参见 5.15）运算符的左操作数,
   或者
   — A 是条件 (?:, 见 5.16) 运算符的左操作数，或
   — A 是内置逗号 (,) 运算符 (5.18) 的左操作数;
   or
   — A 写入一个标量对象或位域 M ，B 从 M 读取 A 写入的值，并且 A 在 B 之前排序，或者
   — 对于某些评估 X ， A 携带对 X 的依赖，并且 X 携带对 B 的依赖.
   [注意：“携带依赖项”是“之前排序”的子集，同样严格地在线程内。 ——尾注]
> An evaluation A carries a dependency to an evaluation B if
   — the value of A is used as an operand of B, unless:
   — B is an invocation of any specialization of std::kill_dependency (29.3), or
   — A is the left operand of a built-in logical AND (&&, see 5.14) or logical OR (||, see 5.15) operator,
   or
   — A is the left operand of a conditional (?:, see 5.16) operator, or
   — A is the left operand of the built-in comma (,) operator (5.18);
   or
   — A writes a scalar object or bit-field M , B reads the value written by A from M , and A is sequenced
   before B, or
   — for some evaluation X , A carries a dependency to X , and X carries a dependency to B.
   [ Note: “Carries a dependency to” is a subset of “is sequenced before”, and is similarly strictly intra-thread. — end note ]


10. 评估 A 在评估 B 之前是依存排序的，如果
    — A 对原子对象 M 执行释放操作，并且在另一个线程上，B 对 M 执行消耗操作并读取由 A 为首的释放序列中的任何副作用写入的值，或
    — 对于某些评估 X ， A 在 X 和 X 携带对 B 的依赖项之前是依赖排序的.
    [注意：关系“之前依赖排序”类似于“同步”，但使用释放/消费代替释放/获取。 ——尾注]
> An evaluation A is dependency-ordered before an evaluation B if
    — A performs a release operation on an atomic object M , and, on another thread, B performs a consume
    operation on M and reads a value written by any side effect in the release sequence headed by A, or
    — for some evaluation X , A is dependency-ordered before X and X carries a dependency to B.
    [ Note: The relation “is dependency-ordered before” is analogous to “synchronizes with”, but uses release/consume in place of release/acquire. — end note ]

11. 评估 A 线程间发生在评估 B 之前，如果
    — A 与 B 同步，或
    — A 在 B 之前是依赖排序的，或者
    — 对于一些评估 X
    — A 与 X 同步并且 X 在 B 之前排序，或者
    — A 在 X 之前排序，并且 X 线程间发生在 B 之前，或者
    — 线程间发生在 X 之前，而 X 线程间发生在 B 之前.
    [ 注意：“线程间发生之前”关系描述了“sequenced before”、“synchronizes with”和“dependency-ordered before”关系的任意连接，但有两个例外。第一个例外是串联不允许以“dependency-ordered before”后跟“sequenced before”结尾。这种限制的原因是，参与“依赖排序之前”关系的消费操作仅针对该消费操作实际携带依赖关系的操作提供排序。此限制仅适用于此类连接的末尾的原因是任何后续发布操作都将为先前的消费操作提供所需的排序.
    第二个例外是不允许串联完全由“sequenced before”组成.
    这种限制的原因是（1）允许“线程间发生之前”被传递关闭，（2）下面定义的“发生之前”关系提供了完全由“顺序之前”组成的关系。 ——尾注]
> An evaluation A inter-thread happens before an evaluation B if
    — A synchronizes with B, or
    — A is dependency-ordered before B, or
    — for some evaluation X
    — A synchronizes with X and X is sequenced before B, or
    — A is sequenced before X and X inter-thread happens before B, or
    — A inter-thread happens before X and X inter-thread happens before B.
    [ Note: The “inter-thread happens before” relation describes arbitrary concatenations of “sequenced before”, “synchronizes with” and “dependency-ordered before” relationships, with two exceptions. The first exception is that a concatenation is not permitted to end with “dependency-ordered before” followed by “sequenced before”. The reason for this limitation is that a consume operation participating in a “dependency-ordered before” relationship provides ordering only with respect to operations to which this consume operation actually carries a dependency. The reason that this limitation applies only to the end of such a concatenation is that any subsequent release operation will provide the required ordering for a prior consume operation.
    The second exception is that a concatenation is not permitted to consist entirely of “sequenced before”.
    The reasons for this limitation are (1) to permit “inter-thread happens before” to be transitively closed and (2) the “happens before” relation, defined below, provides for relationships consisting entirely of “sequenced before”. — end note ]

12. An evaluation A happens before an evaluation B if:
    — A is sequenced before B, or
    — A inter-thread happens before B.
    The implementation shall ensure that no program execution demonstrates a cycle in the “happens before” relation. [ Note: This cycle would otherwise be possible only through the use of consume operations. — end note ]

13. A visible side effect A on a scalar object or bit-field M with respect to a value computation B of M satisfies
    the conditions:
    — A happens before B and
    — there is no other side effect X to M such that A happens before X and X happens before B.
    The value of a non-atomic scalar object or bit-field M , as determined by evaluation B, shall be the value stored by the visible side effect A. [ Note: If there is ambiguity about which side effect to a non-atomic object or bit-field is visible, then the behavior is either unspecified or undefined. — end note ] [ Note: This states that operations on ordinary objects are not visibly reordered. This is not actually detectable without data races, but it is necessary to ensure that data races, as defined [CA 17] herebelow, and with suitable restrictions on the use of atomics, correspond to data races in a simple interleaved (sequentially consistent) execution. — end note ]

14. The visible sequence of side effects on an atomic object M , with respect to a value computation B of M , is a maximal contiguous sub-sequence of side effects in the modification order of M , where the first side effect is visible with respect to B, and for every side effect, it is not the case that B happens before it. The value of an atomic object M , as determined by evaluation B, shall be the value stored by some operation in the visible sequence of M with respect to B. [ Note: It can be shown that the visible sequence of side effects of a value computation is unique given the coherence requirements below. — end note ]

15. If an operation A that modifies an atomic object M happens before an operation B that modifies M , then A shall be earlier than B in the modification order of M . [ Note: This requirement is known as write-write coherence. — end note ]

16. If a value computation A of an atomic object M happens before a value computation B of M , and A takes its value from a side effect X on M , then the value computed by B shall either be the value stored by X or the value stored by a side effect Y on M , where Y follows X in the modification order of M . [ Note: This requirement is known as read-read coherence. — end note ]

17. If a value computation A of an atomic object M happens before an operation B on M , then A shall take its value from a side effect X on M , where X precedes B in the modification order of M . [ Note: This requirement is known as read-write coherence. — end note ]

18. If a side effect X on an atomic object M happens before a value computation B of M , then the evaluation B shall take its value from X or from a side effect Y that follows X in the modification order of M . [ Note: This requirement is known as write-read coherence. — end note ]

19. [ Note: The four preceding coherence requirements effectively disallow compiler reordering of atomic operations to a single object, even if both operations are relaxed loads. This effectively makes the cache coherence guarantee provided by most hardware available to C++ atomic operations. — end note ]

20. [ Note: The visible sequence of side effects depends on the “happens before” relation, which depends on the values observed by loads of atomics, which we are restricting here. The intended reading is that there must exist an association of atomic loads with modifications they observe that, together with suitably chosen modification orders and the “happens before” relation derived as described above, satisfy the resulting constraints as imposed here. — end note ]

21. The execution of a program contains a data race if it contains two conflicting actions in different threads, at least one of which is not atomic, and neither happens before the other. Any such data race results in undefined behavior. [ Note: It can be shown that programs that correctly use mutexes and memory_order_-seq_cst operations to prevent all data races and use no other synchronization operations behave as if the operations executed by their constituent threads were simply interleaved, with each value computation of an object being taken from the last side effect on that object in that interleaving. This is normally referred to as “sequential consistency”. However, this applies only to data-race-free programs, and data-race-free programs cannot observe most program transformations that do not change single-threaded program semantics. In fact, most single-threaded program transformations continue to be allowed, since any program that behaves differently as a result must perform an undefined operation. — end note ]

22. [ Note: Compiler transformations that introduce assignments to a potentially shared memory location that would not be modified by the abstract machine are generally precluded by this standard, since such an assignment might overwrite another assignment by a different thread in cases in which an abstract machine execution would not have encountered a data race. This includes implementations of data member assignment that overwrite adjacent members in separate memory locations. Reordering of atomic loads in cases in which the atomics in question may alias is also generally precluded, since this may violate the “visible sequence” rules. — end note ]

23. [ Note: Transformations that introduce a speculative read of a potentially shared memory location may not preserve the semantics of the C++ program as defined in this standard, since they potentially introduce a data race. However, they are typically valid in the context of an optimizing compiler that targets a specific machine with well-defined semantics for data races. They would be invalid for a hypothetical machine that is not tolerant of races or provides hardware race detection. — end note ]

24. The implementation may assume that any thread will eventually do one of the following:
    — terminate,
    — make a call to a library I/O function,
    — access or modify a volatile object, or
    — perform a synchronization operation or an atomic operation.
    [ Note: This is intended to allow compiler transformations such as removal of empty loops, even when termination cannot be proven. — end note ]

25. An implementation should ensure that the last value (in modification order) assigned by an atomic or synchronization operation will become visible to all other threads in a finite period of time.

#### 29. Atomic operations library

#### 30. Thread support library

<!-- ## c++ 内存模型编译器支持 -->

<!-- ## c++ thread 库 -->

## 内存模型编译器支持

## [一些其他问题](https://www.hboehm.info/c++mm/faq.html)

这是试图总结对常见问题/反对意见的回应，以在我们看来确实有明确回应的 C++ 线程上的工作。我们仍在研究一些更难的问题...

### 为什么这被作为 C++ 问题而不是 Posix/线程库问题来解决?

正如 H. Boehm 所指出的，[“线程不能作为库实现”，PLDI 2005](http://portal.acm.org/citation.cfm?doid=1065010.1065042) 或 [技术报告版本]( http://www.hpl.hp.com/techreports/2004/HPL-2004-209.html），当前 C++/pthreads 线程方法的根本困难在于 C++ 编译器可以引入数据竞争在源头。这基本上是语言规范和编译器问题，不能通过更改线程库规范来解决。


### 为什么将其作为 C++ 而不是 C 问题解决?

从历史上看，原因是我们中的一些人与 C++ 委员会有更好的联系。在这一点上，一个更好的理由是 C++ 委员会正在积极致力于修订语言规范，但 C 委员会没有。我们正在努力让 C 委员会了解情况，并希望他们最终会采用一些 C++ 更改，可能作为技术报告而不是完整的标准修订.


### 为什么不能通过声明相关的共享变量 volatile 来回避编译器优化问题?

事实证明这是不切实际的，有几个原因:
- 先前引用的 PLDI 论文中的编译器引入的数据竞争的示例主要处理共享变量（例如 x 已受锁保护）的情况。因此，我们必须要求程序员声明受锁保护的变量，即内部监控变量 volatile。这显然不是 pthread 标准的意图。 （参见 SUSV3 中内存同步的讨论。）
更重要的是，这被证明是完全不切实际的。将单线程代码 "包装" 在锁中以使其在多线程应用程序中可用是很常见的。如果现在必须将单线程代码中的所有变量/字段声明为 volatile，这将是不可能的。 C++ 标准库的线程安全版本有效地依赖于这种方法，我们认为这是唯一可行的方法。它也类似于最近的 Java 容器库所采用的，例如.

- 要求锁保护变量的 volatile 声明实际上需要大多数库有两个版本：一个标准版本，一个所有内部静态变量都声明为 volatile.

- 构建编译器在变量上引入竞争的示例并不难，该变量实际上应该只能由单个线程访问。 （对于一个这样的例子，请参阅 WG14 论文 N1131。）因此，我们还必须告诉程序员将非共享变量声明为 volatile，如果它可以让编译器看起来好像它们可能是共享的。在我们看来，这是一个完全不合理的要求.

- 除了前面两个问题之外，还不清楚 volatile 是否为多线程程序提供了有意义的保证，或者这些保证是什么。 Dave Butenhof 经常被引用说 "**使用 `volatile` 不足以确保正确的内存可见性或线程之间的同步。**"


### 为什么不能只采用 Java 内存模型?

Java 内存模型的主要动机是希望同时保留类型安全和其他一些安全保证，如果要在不受信任的代码与受信任的代码相同的地址空间中运行，这两者都是必不可少的。由于这对于普通的 C 或 C++ 代码来说在任何情况下都是不可能的，因此不再需要考虑.

此外，似乎为 C++ 提供类似 Java 的保证可能很昂贵，特别是在提供弱内存模型或为普通存储提供弱原子性保证的架构上。例如，实现必须确保对象指针不能从一个线程传递到另一个线程，除非事先使对象 vtable 指针对另一个线程可见。这可能在对象构造期间需要内存屏障。与 Java 程序员不同，**C++ 程序员倾向于期望对象构造是一种非常轻量级的操作**.

然而，我们似乎越来越有可能大量借鉴 Java 内存模型，特别是**解释 C++ 原子操作的语义**.


### 为什么不能只采用 CLI 内存模型?

请参阅上一个问题的答案。 CLI 内存模型似乎仍然是一个移动目标.

## 参考
- [c++mm 相关参考](https://www.hboehm.info/c++mm/)
- [c++mm 线程介绍](https://www.hboehm.info/c++mm/threadsintro.html)
- todo: more
